{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math \n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gradient descent elements\n",
    "def vector_subtract(v,w):\n",
    "    \"\"\" subtracts corresponding elements of two vectors \"\"\"\n",
    "    return [v_i - w_i for v_i,w_i in zip(v,w)]\n",
    "\n",
    "def sum_of_squares(v):\n",
    "    squares = [v_i ** 2 for v_i in v]\n",
    "    return sum(squares)\n",
    "\n",
    "def magnitude(v):\n",
    "    # length of a vector in projection\n",
    "    # basically get the hypotenuse\n",
    "    return math.sqrt(sum_of_squares(v))\n",
    "\n",
    "def distance(v,w):\n",
    "    \"\"\" distance between two vectors \"\"\"\n",
    "    return magnitude(vector_subtract(v,w))\n",
    "\n",
    "def step(v,direction,step_size):\n",
    "    return [v_i + step_size * direction_i\n",
    "        for v_i, direction_i in zip(v,direction)]\n",
    "\n",
    "def sum_of_squares_gradient(v):\n",
    "    return [2 * v_i for v_i in v]\n",
    "\n",
    "def safe(f):\n",
    "    def safe_f(*args, **kwargs):\n",
    "        try:\n",
    "            return f(*args,**kwargs)\n",
    "        except:\n",
    "            return float('inf')\n",
    "    return safe_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "def minimize_batch(target_fn,gradient_fn,theta_0,tolerance=0.000001):\n",
    "    \"\"\" use gradient descent to fined theta that minimizeds the target function \"\"\"\n",
    "    step_sizes = [100,10,1,0.1,0.01,0.001,0.0001,0.00001]\n",
    "    \n",
    "    theta = theta_0\n",
    "    target_fn = safe(target_fn)\n",
    "    value = target_fn(theta)\n",
    "    \n",
    "    while True: \n",
    "        gradient = gradient_fn(theta)\n",
    "        next_thetas = [step(theta,gradient, -step_size) for\n",
    "                      step_size in step_sizes]\n",
    "        \n",
    "        # choose the one that minimizes the error function\n",
    "        next_theta = min(next_thetas, key=target_fn)\n",
    "        next_value = target_fn(next_thetas)\n",
    "        \n",
    "        # stop if convergence\n",
    "        if abs(value - next_value) < tolerance:\n",
    "            return theta\n",
    "        else:\n",
    "            theta, value = next_theta,next_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stochastic gradient descent\n",
    "def in_random_order(data):\n",
    "    \"\"\" generator that returns the element of data in random order \"\"\"\n",
    "    indexes = [i for i, _ in enumerate(data)]\n",
    "    random.shuffle(indexes)\n",
    "    for i in indexes:\n",
    "        yield data[i]\n",
    "        \n",
    "def minimize_stochastic(target_fn,gradient_fn,x,y,theta_0,alpha_0=0.01):\n",
    "    data = zip(x,y)\n",
    "    theta = theta_0\n",
    "    alpha = alpha_0\n",
    "    min_theta, min_value = None, float(\"inf\")\n",
    "    iterations_with_no_improvement = 0\n",
    "    \n",
    "    # if we go 100 iterations with no improvement stop\n",
    "    while iterations_with_no_improvement < 0:\n",
    "        value = sum(target_fn(x_i,y_i,theta) for x_i,y_i in data)\n",
    "        \n",
    "        if value < min_value:\n",
    "            # if we found a new minumum, remember it\n",
    "            min_theta, min_value = theta,value\n",
    "            iterations_with_no_improvement = 0\n",
    "            alpha = alpha_0\n",
    "        else:\n",
    "            # if there are no improvements, shrink the step size\n",
    "            iterations_with_no_improvement += 1\n",
    "            alpha *= 0.9\n",
    "            \n",
    "        for x_i,y_i in in_random_order(data):\n",
    "            gradient_i = gradient_fn(x_i,y_i,theta)\n",
    "            theta = vector_subtract(theta,scalar_multiply(alpha,gradient_i))\n",
    "            \n",
    "    return min_theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dimension reduction elements\n",
    "# from old chapters\n",
    "def dot(a,b):\n",
    "    return sum([a[i] * b[i] for i,_ in enumerate(a)])\n",
    "\n",
    "def vector_sum(v):\n",
    "    return sum(v)\n",
    "\n",
    "#from current chapter\n",
    "def direction(w):\n",
    "    mag = magnitude(w)\n",
    "    return [w_i/mag for w_i in w]\n",
    "\n",
    "def directional_variance_i(x_i, w):\n",
    "    \"\"\" The variance of he row x_i in the direction determined by w \"\"\"\n",
    "    return dot(x_i, direction(w)) ** 2\n",
    "\n",
    "def directional_variance(X, w):\n",
    "    \"\"\" variance of the data i the direction determined by w \"\"\"\n",
    "    return sum(directional_variance_i(x_i,w) for x_i in X)\n",
    "\n",
    "def directional_variance_gradient_i(x_i, w):\n",
    "    \"\"\" The variance of he row x_i in the direction determined by w \"\"\"\n",
    "    projection_length = dot(x_i,direction(w))\n",
    "    return [2* projection_length * x_ij for x_ij in x_i]\n",
    "\n",
    "def directional_variance_gradient(X, w):\n",
    "    \"\"\" variance of the data i the direction determined by w \"\"\"\n",
    "    return vector_sum(directional_variance_gradient_i(x_i,w) for x_i in X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18257418583505536,\n",
       " 0.3651483716701107,\n",
       " 0.5477225575051661,\n",
       " 0.7302967433402214]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direction([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.477225575051661"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magnitude([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,3,-5]\n",
    "b = [4,-2,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
